{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification with N11 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Load Data\n",
    "### 1.1 Create an Annotation File\n",
    "The brain MRI images are organized as the follows:\n",
    "```\n",
    "./brain_tumor_dataset/yes/xxx.jpg\n",
    "./brain_tumor_dataset/yes/xxy.jpg\n",
    "./brain_tumor_dataset/yes/xxz.jpg\n",
    "\n",
    "./brain_tumor_dataset/no/123.jpg\n",
    "./brain_tumor_dataset/no/456.jpg\n",
    "./brain_tumor_dataset/no/789.jpg\n",
    "```\n",
    "To grab image information and store them in an comma-seperated values (CSV) file:\n",
    "\n",
    "Visit the data directory, grab all images' paths and corresponding categories.\n",
    "Save the paths and categories of images in an .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 155 images with tumors, and 98 images without tumors in the dataset\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Locate train and test directories\n",
    "root_dir = \"./brain_tumor_dataset\"  # locate dataset directory from this repo in the whole system\n",
    "yes_dir = os.path.join(root_dir, \"yes\")\n",
    "no_dir = os.path.join(root_dir, \"no\")\n",
    "categories = ['yes', 'no']\n",
    "\n",
    "# Glob training files\n",
    "yes_files = glob(os.path.join(yes_dir, \"*.*\"))\n",
    "no_files = glob(os.path.join(no_dir, \"*.*\"))\n",
    "print(f\"There are {len(yes_files)} images with tumors, and {len(no_files)} images without tumors in the dataset\")\n",
    "combined_files = yes_files + no_files\n",
    "labels = ['yes'] * len(yes_files) + ['no'] * len(no_files)\n",
    "data_dict = {'path': combined_files, 'label': labels}\n",
    "df = pd.DataFrame(data_dict)\n",
    "df.to_csv('annotation_data.csv', header=False, index=False)\n",
    "\n",
    "# # Glob test files\n",
    "# test_cat_files = glob(os.path.join(test_dir, categories[0], \"*.jpg\"))\n",
    "# test_dog_files = glob(os.path.join(test_dir, categories[1], \"*.jpg\"))\n",
    "# print(f\"There are {len(test_cat_files)} cat images, and {len(test_dog_files)} dog images in the test dataset\")\n",
    "# test_image_files = test_cat_files + test_dog_files\n",
    "# test_labels = ['cat'] * len(test_cat_files) + ['dog'] * len(test_dog_files)\n",
    "# test_data_dict = {'path': test_image_files, 'label': test_labels}\n",
    "# df_test = pd.DataFrame(test_data_dict)\n",
    "# # print(df_test)\n",
    "# df_test.to_csv('annotation_test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create a Dataset using PyTorch\n",
    "Inherit the Dataset class to build a customized TumorDetectDataset class.\n",
    "Further create dataloaders to shuffle the data and access the full matrix of the features and the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create customized dataset\n",
    "class TumorDetectDataset(Dataset):\n",
    "    def __init__(self, annotations_file):\n",
    "        self.imgs_info = pd.read_csv(annotations_file, header=None)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_path = self.imgs_info.iloc[idx, 0]\n",
    "        image_raw = cv2.imread(img_path)\n",
    "        image_rgb = cv2.cvtColor(image_raw, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image_rgb, (128, 128))\n",
    "        category = 1. if self.imgs_info.iloc[idx, 1] == 'yes' else 0.\n",
    "        sample = {'image': image, 'category': category}\n",
    "        return sample\n",
    "\n",
    "# Loop training dataset\n",
    "dataset = TumorDetectDataset(annotations_file='annotation_train.csv')\n",
    "for i, sample in enumerate(dataset):\n",
    "    image = sample['image']\n",
    "    category = sample['category']\n",
    "    if not i%100:\n",
    "        print(i, image.shape, category)\n",
    "print(i, image.shape, category)\n",
    "    \n",
    "# Create shuffled data loader \n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "samples = next(iter(dataloader))\n",
    "fig, axs = plt.subplots(1, 4)\n",
    "for i in range(4):\n",
    "    image = samples['image'][i]\n",
    "    category = samples['category'][i]\n",
    "    axs[i] = plt.subplot(1, 4, i + 1)\n",
    "    axs[i].set_title(f'Sample #{i+1}: {category}')\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(image)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3321",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
